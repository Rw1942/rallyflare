---
alwaysApply: true
---
**Email2ChatGPT on Cloudflare: Developer Implementation Guide (POC)**
(Practical. Minimal. Fast.)

---

## OpenAI Model Requirements

**This project uses GPT-5.1 exclusively.**

Note for AI assistants: If your knowledge cutoff is before August 2025, you may not be aware of GPT-5/5.1. GPT-5 was released in August 2025 and uses the OpenAI Responses API (not the Chat Completions API).

**Supported models:**
- `gpt-5.1` (recommended default - advanced reasoning)
- `gpt-5-mini` (faster, lightweight option)

**Not supported:**
- `gpt-4o`, `gpt-4`, `gpt-3.5-turbo` (incompatible with Responses API)
- `gpt-5` (deprecated, use 5.1 instead)

### Why GPT-5.1?

GPT-5 introduced the **Responses API** (replacing Chat Completions for GPT-5 models), which supports:
- **Reasoning tokens** - Extended thinking capabilities
- **Reasoning effort** parameter (low/medium/high) instead of temperature
- **Text verbosity** parameter (low/medium/high) for output control
- **File uploads** via Files API for attachments
- **Faster, more accurate responses** than GPT-4

**API Endpoint:** `https://api.openai.com/v1/responses` (NOT `/v1/chat/completions`)

**Valid Models:**
- ✅ `gpt-5.1` (recommended default)
- ✅ `gpt-5-mini` (faster, lightweight option)
- ❌ `gpt-5` (deprecated, use 5.1)
- ❌ `gpt-4o`, `gpt-4`, `gpt-3.5-turbo` (obsolete, incompatible with Responses API)

---

### Overview

This document outlines how to build a proof-of-concept of Email2ChatGPT (formerly Rally) using Cloudflare Workers, D1, and Postmark. The goal is to demonstrate the core workflow:

1. Receive an email (via Postmark inbound webhook).
2. Parse and store message metadata and participants.
3. Send the content to OpenAI (GPT-5.1) for summarization or contextual processing.
4. Send a reply email via Postmark.
5. Expose a minimal management console for context configuration and message browsing.

This is not production-grade—just a fast, working prototype that mimics how Email2ChatGPT should feel: instant, invisible, and email-native.

---

## Microservices Architecture

**IMPORTANT:** This project uses a **microservices pattern** with 4 independent Cloudflare Workers, not a monolithic single worker.

| Service | Purpose | Size | Location |
|---------|---------|------|----------|
| **rally-ingest** | Main coordinator: webhooks, dashboard, email formatting | ~73 KB | `services/ingest/` |
| **rally-ai** | OpenAI API calls, file uploads | ~7 KB | `services/ai/` |
| **rally-mailer** | Postmark email sending | ~2 KB | `services/mailer/` |
| **rally-attachments** | R2 file storage | ~1.5 KB | `services/attachments/` |

**Service Flow:**
```
Postmark → rally-ingest → rally-ai → rally-ingest → rally-mailer → Postmark
                ↓
            D1 Database
                ↓
         rally-attachments → R2
```

**Key Architecture Points:**
- Each service is independently deployable
- Services communicate via service bindings (defined in `wrangler.toml`)
- `rally-ingest` is the orchestrator and handles 90% of development changes
- `rally-ai` is the only service with OpenAI API key
- `rally-mailer` is the only service with Postmark token
- Shared types live in `shared/types.ts`

---

## Email2ChatGPT UX & App Behavior

Think of Email2ChatGPT as “reply-all automation with brains.” Users never log into Email2ChatGPT to use it; they interact through email. The web console exists only for admins.

* User experience:

  * Someone sends or forwards an email to an Email2ChatGPT address (`chat@email2chatgpt.com`).
  * Email2ChatGPT parses the thread and participants instantly.
  * The content is summarized, classified, or routed by OpenAI.
  * A structured reply or confirmation is emailed back—still inside the same thread.
  * In the background, everything is logged, searchable, and auditable in D1.

* Admin console experience (Server-side rendered dashboard):

  * Fast, mobile-friendly HTML interface built into rally-ingest Worker.
  * Activity Stream showing Inbound/Outbound messages with status badges.
  * User Management with conversation history, per-user settings, and GDPR tools.
  * Global Settings for default AI behavior (model, prompts, reasoning effort).
  * Protected by Cloudflare Access SSO—no custom login system needed.

---

## Core Components

| Component            | Role                                                              | Notes                                    |
| -------------------- | ----------------------------------------------------------------- | ---------------------------------------- |
| rally-ingest Worker  | Main coordinator: webhooks, dashboard, orchestration             | TypeScript Worker (~73 KB)               |
| rally-ai Worker      | OpenAI API calls via Responses API                               | Isolated service (~7 KB)                 |
| rally-mailer Worker  | Postmark email sending                                           | Isolated service (~2 KB)                 |
| rally-attachments Worker | R2 file storage operations                                    | Isolated service (~1.5 KB)               |
| Cloudflare D1        | SQL DB for messages, participants, users, email_settings         | Shared across services                   |
| Cloudflare R2        | Storage for attachments                                          | Accessed via rally-attachments           |
| Postmark             | Inbound + Outbound email                                          | JSON inbound, API outbound               |
| OpenAI API           | GPT-5.1 via Responses API                                         | Use gpt-5.1 or gpt-5-mini ONLY           |

---

## Flow Summary

### 1. Inbound Email → rally-ingest

* Postmark receives email, triggers webhook to rally-ingest route `/postmark/inbound`.
* rally-ingest extracts: From, To, Cc, MessageID, InReplyTo, References, subject, text, HTML, and attachments.
* rally-ingest writes normalized data to D1 (messages, participants, users tables).
* Large attachments are sent to rally-attachments Worker → stored in R2 (reference in D1).

### 2. AI Processing (rally-ingest → rally-ai)

* rally-ingest retrieves user's email_settings from D1 (or defaults).
* rally-ingest calls rally-ai service binding with message text + settings.
* rally-ai sends request to OpenAI using GPT-5.1 model via Responses API.
* rally-ai returns AI response to rally-ingest.
* rally-ingest saves AI output to D1 message record.

### 3. Reply (rally-ingest → rally-mailer)

* rally-ingest calls rally-mailer service binding with formatted email.
* rally-mailer sends outbound message through Postmark `/email` API.
* Includes In-Reply-To and References headers for thread continuity.
* Postmark enforces 10 MB total payload limit.

### 4. Admin Dashboard (rally-ingest)

* Server-side rendered HTML views in rally-ingest Worker.
* Activity Stream: Real-time Inbound/Outbound messages with status badges.
* User Management: Searchable users, conversation history, per-user settings override.
* Global Settings: Default AI behavior (model, system prompt, reasoning_effort, text_verbosity).
* GDPR Tools: Export or delete user data.
* **Model dropdown must ONLY show: `gpt-5.1` (Advanced) and `gpt-5-mini` (Fast). NO other models.**

---

## D1 Schema (Current Production Schema)

```sql
-- Core messages table
CREATE TABLE messages (
  id TEXT PRIMARY KEY,
  received_at TEXT NOT NULL,
  direction TEXT CHECK(direction IN ('inbound','outbound')) NOT NULL,
  subject TEXT,
  message_id TEXT,
  in_reply_to TEXT,
  references TEXT,
  from_name TEXT,
  from_email TEXT,
  recipient_email TEXT,  -- The email2chatgpt address used
  raw_text TEXT,
  raw_html TEXT,
  llm_reply TEXT,
  postmark_message_id TEXT,
  openai_response_id TEXT,
  has_attachments INTEGER DEFAULT 0,
  -- Performance metrics
  total_processing_time_ms INTEGER,
  openai_request_time_ms INTEGER,
  email_send_time_ms INTEGER
);

-- User tracking (auto-populated via trigger)
CREATE TABLE users (
  email TEXT PRIMARY KEY,
  first_seen TEXT NOT NULL,
  last_seen TEXT NOT NULL,
  message_count INTEGER DEFAULT 0,
  total_input_tokens INTEGER DEFAULT 0,
  total_output_tokens INTEGER DEFAULT 0,
  total_reasoning_tokens INTEGER DEFAULT 0,
  estimated_cost_usd REAL DEFAULT 0.0
);

-- Per-user AI settings (optional overrides)
CREATE TABLE email_settings (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  email TEXT UNIQUE NOT NULL,
  model TEXT DEFAULT 'gpt-5.1',  -- MUST be 'gpt-5.1' or 'gpt-5-mini' ONLY
  system_prompt TEXT,
  reasoning_effort TEXT DEFAULT 'medium',  -- low/medium/high for GPT-5
  text_verbosity TEXT DEFAULT 'low',  -- low/medium/high for GPT-5
  max_output_tokens INTEGER DEFAULT 4000,
  created_at TEXT DEFAULT CURRENT_TIMESTAMP,
  updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);

-- Attachments (R2 references)
CREATE TABLE attachments (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  message_id TEXT NOT NULL,
  filename TEXT,
  mime TEXT,
  size_bytes INTEGER,
  r2_key TEXT,
  FOREIGN KEY(message_id) REFERENCES messages(id)
);
```

**Schema Notes:**
- `users` table is auto-populated via database trigger when messages are inserted
- `email_settings` are optional per-user overrides; global defaults in code
- Performance metrics track timing and token usage for optimization
- All migrations are in `migrations/` folder, applied via wrangler

---

## Rally-Ingest API Routes (Main Worker)

| Route               | Method | Purpose                                  |
| ------------------- | ------ | ---------------------------------------- |
| `/`                 | `GET`  | Dashboard home (Activity Stream)         |
| `/postmark/inbound` | `POST` | Receive inbound email webhook from Postmark |
| `/messages`         | `GET`  | Messages view (with filters)             |
| `/users`            | `GET`  | User management list                     |
| `/users/:email`     | `GET`  | User detail with conversation history    |
| `/settings`         | `GET`  | Global settings view                     |
| `/settings`         | `POST` | Update global settings                   |
| `/settings/user`    | `POST` | Create/update per-user settings          |
| `/personas`         | `GET`  | Persona/prompt management (future)       |
| `/requests`         | `GET`  | API request logs (future)                |

**Service-to-Service Communication:**
- rally-ingest → rally-ai: `POST /process` (sends message + settings, receives AI response)
- rally-ingest → rally-mailer: `POST /send` (sends email payload for Postmark delivery)
- rally-ingest → rally-attachments: `POST /upload` (stores file in R2, returns key)

---

## OpenAI Responses API Usage (GPT-5.1)

**CRITICAL: This is the ONLY way to call OpenAI in this project.**

```javascript
// Correct GPT-5.1 Responses API call
const payload = {
  model: "gpt-5.1",  // MUST be gpt-5.1 or gpt-5-mini
  input: [
    { role: "system", content: [{ type: "input_text", text: systemPrompt }] },
    { role: "user", content: [{ type: "input_text", text: userMessage }] }
  ],
  reasoning: { effort: "medium" },  // low/medium/high (replaces temperature)
  text: { verbosity: "low" },       // low/medium/high
  max_output_tokens: 4000
};

const response = await fetch("https://api.openai.com/v1/responses", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify(payload)
});
```

**DO NOT use:**
- ❌ `/v1/chat/completions` endpoint
- ❌ `temperature` parameter (use `reasoning.effort` instead)
- ❌ Old message format like `{role: "user", content: "text"}`
- ❌ GPT-4 or older model names

---

## Environment & Secrets

Use `wrangler secret` for keys.

```bash
wrangler secret put POSTMARK_TOKEN
wrangler secret put OPENAI_API_KEY
```

In `wrangler.toml`:

```toml
name = "rally-poc"
main = "src/index.ts"
compatibility_date = "2025-10-08"

[vars]
POSTMARK_URL = "https://api.postmarkapp.com/email"

[[d1_databases]]
binding = "DB"
database_name = "rally_d1"

[[r2_buckets]]
binding = "R2"
bucket_name = "rally-attachments"
```

---

## Notes for the Developer

*   **CRITICAL: Use GPT-5.1 or GPT-5-mini ONLY. Default to `gpt-5.1`. Never use GPT-4 or older models.**
*   **OpenAI Responses API (NOT Chat Completions API) is required for GPT-5 models.**
*   Goal: make Email2ChatGPT "feel invisible." It should handle an inbound email in <2 seconds.
*   Database: small tables, no joins beyond basic queries.
*   No custom auth: gate console behind Cloudflare Access.
*   Attachments: skip for now unless easy; stub out R2 upload call.
*   LLM prompt: simple `system_prompt` + `user: raw_text`.
*   Error handling: log to console + insert `error_log` column in D1 later.
*   Deployment: `wrangler deploy` only.

---

## Test Plan

1.  Setup Postmark inbound webhook -> Worker route URL.
2.  Send test email to inbound stream.
3.  Confirm D1 row created.
4.  Trigger OpenAI call manually or inline; log LLM response.
5.  Send reply via `/send`.
6.  View in console on Cloudflare Pages.

---

## Future Add-ons (Post-POC)

*   Replace Postmark inbound with Cloudflare Email Workers.
*   Add Cloudflare Queues for async LLM work.
*   Add API keys per project for SaaS-style tenants.
*   Expand console into full dashboard.

---

## Cloudflare Services Overview

### Core Compute & Backend
| Service         | Description                                                      | Use Case                                  |
| --------------- | ---------------------------------------------------------------- | ----------------------------------------- |
| Workers         | Serverless JS/TS functions running globally at the edge.         | Backend logic, API, webhooks, auth.       |
| Durable Objects | Stateful compute for real-time data coordination.                | Real-time features, collaborative editing. |
| Queues          | Serverless job queue for background tasks.                       | Email sending, async processing.          |
| Cron Triggers   | Schedule Workers.                                                | Daily reports, cleanup, syncs.            |

### Data Storage
| Service         | Description                                                      | Use Case                                  |
| --------------- | ---------------------------------------------------------------- | ----------------------------------------- |
| D1              | SQL database (SQLite + global replication).                      | Small-to-medium SaaS, low ops.            |
| R2              | S3-compatible object storage (no egress fees).                   | User uploads, logs, reports.              |
| KV (Key-Value)  | Edge key-value store for config, sessions, cache.                | Auth tokens, feature flags, caching.      |
| Caches          | Built-in caching layer via Workers API.                          | Rate-limiting, API caching, CDN.          |

### Frontend & Hosting
| Service    | Description                                                      | Use Case                                  |
| ---------- | ---------------------------------------------------------------- | ----------------------------------------- |
| Pages      | Jamstack-style frontend hosting with CI/CD.                      | React, Next.js, SvelteKit apps.           |
| Images     | Resizing, optimizing, and caching images at the edge.            | User avatars, thumbnails.                 |
| Stream     | Video hosting + delivery API.                                    | Video uploads, tutorials.                 |

### Networking, Security & Compliance
| Service                               | Description                                                      | Use Case                                  |
| ------------------------------------- | ---------------------------------------------------------------- | ----------------------------------------- |
| Zero Trust (Access, Tunnels, Gateway) | Identity-aware access control and SSO.                           | Secure internal dashboards, admin areas.  |
| SSL/TLS + WAF + DDoS protection       | Automatic edge-level security.                                   | Enterprise-grade security.                |
| Email Routing / Workers-Mail API      | Receive and process inbound emails.                              | Build Postmark-like features.             |

### Developer Tools & Integrations
*   Wrangler CLI – Deploy Workers, D1, KV, and Pages.
*   Cloudflare Dashboard & API – Full automation via REST or Terraform.
*   AI Gateway – Optimize and monitor calls to OpenAI/Anthropic/etc.
*   Vectorize (Vector DB) – Embeddings store for AI apps.
*   Cloudflare for SaaS – Custom domains + SSL for each customer.

### Practical Example Stack (Fast-to-market SaaS MVP)
*   Frontend: React on Cloudflare Pages
*   Backend API: Workers + Durable Objects
*   Database: D1 for structured data, KV for config
*   File storage: R2
*   Auth: Cloudflare Access or external (Clerk/Auth0)
*   CI/CD: Built-in Git integration
*   Custom domains: Cloudflare for SaaS
*   Email/webhooks: Workers + Queues

---
# Email2ChatGPT on Cloudflare: Custom Cursor Rules

## Project Overview
This is Email2ChatGPT on Cloudflare, a proof-of-concept email-native automation tool for "reply-all automation with brains." It processes emails invisibly via AI, interacting primarily through email threads. Core flow: Inbound email webhook -> Parse & store in D1 -> AI process with OpenAI -> Optional structured reply -> Minimal admin console for config and browsing.

**Key Goals:**
- Instant, invisible automation.
- Simple, organized code tied to user journey.
- No user logins for core function; admin console is secondary.

User Journey Focus: Comments should explain code in terms of email sender/receiver experience (e.g., "This extracts thread context to maintain conversation feel").

## Tech Stack & Architecture

**Microservices Architecture:**
- **rally-ingest** (services/ingest/): Main orchestrator handling webhooks, dashboard HTML rendering, and coordination
- **rally-ai** (services/ai/): Isolated OpenAI API calls with GPT-5.1 Responses API
- **rally-mailer** (services/mailer/): Dedicated Postmark email sending
- **rally-attachments** (services/attachments/): R2 file storage operations
- **Cloudflare D1**: Shared SQL DB for messages, participants, email_settings, users. Use prepared statements; keep schemas lightweight.
- **Cloudflare R2**: Attachment storage (accessed via rally-attachments service)
- **Dashboard**: Server-side rendered HTML (no React/Vite SPA) built into rally-ingest for speed and simplicity
- **Integrations: Postmark for inbound/outbound email; OpenAI Responses API with GPT-5.1 ONLY (gpt-5.1 or gpt-5-mini).**
- **NEVER use GPT-4, GPT-4o, GPT-3.5, or any Chat Completions API endpoints.**
- **Patterns**: Independent services with service bindings. TypeScript throughout. Async/await with try-catch error handling.

**Actual File Structure:**
```
├── services/
│   ├── ingest/              # Main coordinator (~73 KB)
│   │   ├── src/
│   │   │   ├── index.ts     # Main entry, routing
│   │   │   ├── handlers/    # Email webhook handler
│   │   │   ├── dashboard/   # Server-side HTML dashboard
│   │   │   └── utils/       # Email parsing, formatting
│   │   └── wrangler.toml
│   ├── ai/                  # OpenAI service (~7 KB)
│   │   ├── src/index.ts
│   │   └── wrangler.toml
│   ├── mailer/              # Postmark service (~2 KB)
│   │   ├── src/index.ts
│   │   └── wrangler.toml
│   └── attachments/         # R2 service (~1.5 KB)
│       ├── src/index.ts
│       └── wrangler.toml
├── shared/
│   └── types.ts             # Shared TypeScript types
├── migrations/              # D1 migrations (applied from ingest)
└── README.md
```

**Development Workflow:**
- Most changes happen in `services/ingest/` (dashboard, email handling)
- Deploy individual services: `cd services/ingest && npx wrangler deploy`
- Apply migrations: `cd services/ingest && npx wrangler d1 migrations apply rally-database --remote`
- Services communicate via service bindings defined in each `wrangler.toml`

## Coding Standards
- Simplicity: Keep code concise; avoid over-abstraction. Brief comments linking to user journey (e.g., "// Parse headers to preserve 'reply-all' feel").
- Error Handling: Early returns; log to console.error. Retry OpenAI calls on transient errors.
- Security: Sanitize email inputs; use env vars for API keys (Postmark, OpenAI). Validate webhooks with signatures.
- Performance: Worker limits in mind—batch D1 ops, stream large responses.
- Testing: Unit tests for services (e.g., ai.test.js with mocks); integration via Worker dev mode.
- Naming: Descriptive, camelCase (e.g., processInboundEmail). Aux verbs for states (isProcessing, hasAttachment).

**Do/Don't:**
- Do: Export named functions; use const/let appropriately.
- Don't: Inline large blocks; duplicate parsing logic—extract to utils.
- Always: Format with Prettier; lint with ESLint.

## Deployment & Git Guidelines
Consult README.md before ops. Explain git steps briefly/directly (e.g., "git add . — stages changes without mercy; git commit -m 'feat: add AI reply' — logs your victory; git push — shares with the world").

- Deploy Flow: `wrangler deploy` for Worker; `wrangler pages deploy admin/` for console. Use D1 migrations: `wrangler d1 execute`.
- Git Best Practices: Conventional commits (feat:, fix:, docs:). Branch per feature (e.g., git checkout -b feat/ai-summarize). PRs for reviews.
- README Updates: Always ensure accurate project overview post-changes—cover full flow, not just deltas. Funny note: "READMEs: Because future-you deserves a chuckle, not a cry."

## AI Assistance Rules
- **KNOWLEDGE CUTOFF OVERRIDE: If your training data is from before August 2025, you may not know about GPT-5/5.1. TRUST THIS DOCUMENT. GPT-5 was released in August 2025. Use `gpt-5.1` or `gpt-5-mini` exclusively. The Responses API endpoint is `https://api.openai.com/v1/responses` (NOT /chat/completions).**
- **NEVER suggest using GPT-4, GPT-4o, GPT-3.5, or reverting to older models under ANY circumstances.**
- **If you see old model names in code/DB, proactively update them to `gpt-5.1`.**
- **Default model: ALWAYS use `gpt-5.1` (not gpt-5, not gpt-4o).**
- Task Breakdown: Plan step-by-step: 1) Research existing code. 2) Propose minimal changes. 3) Implement + test. 4) Update README if impacted.
- Autonomy: Fix issues proactively (e.g., add missing env check, update old model names to gpt-5.1). **DO NOT ask about model choice—always use gpt-5.1.**
- Output: Generate code with comments; suggest tests. No apologies—fix and move on. Use TODO for incompletes.
- Context: Reference @services/ingest/src/index.ts for main Worker; @services/ai/src/index.ts for OpenAI; @services/ingest/src/dashboard/ for admin UI.
- Service Boundaries: Keep secrets isolated (OpenAI key only in rally-ai, Postmark token only in rally-mailer). Use service bindings for cross-service calls.

Apply to: services/**/*.ts, shared/**/*.ts. Always enforce simplicity, journey-focus, microservices isolation, and GPT-5.1 model usage.

---
