# GPT-5.1 Developer Guide (REST Only)

Cloudflare Workers • TypeScript • D1 • R2

**IMPORTANT: Model Names**
- **Available Models:**
  - `gpt-5.1` - Advanced reasoning model ($2.50 input / $10.00 output per 1M tokens)
  - `gpt-5-mini` - Faster, cost-effective ($0.25 input / $2.00 output per 1M tokens)
- **Supported Parameters:** `reasoning.effort`, `text.verbosity`, `max_output_tokens`
- **Unsupported Parameters:** `temperature`, `top_p` (will cause 400 errors)

---

## 1. Authentication (Workers-native)

Always use the Worker's env for secure API key injection:

```ts
const headers = (env: Env) => ({
  "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
});
```

---

## 2. Basic Chat Completion (Non-Streaming)

> Clean REST, no SDK required. Email2ChatGPT usage: internal helpers, summaries, draft replies, etc.

```ts
export async function chat(env: Env, prompt: string) {
  const body = {
    model: "gpt-5.1",  // or "gpt-5-mini" for faster, cheaper responses
    input: [{ role: "user", content: prompt }],
    // Supported configuration parameters
    reasoning: { effort: "medium" }, // minimal, low, medium, high
    text: { verbosity: "low" },      // low, medium, high
    max_output_tokens: 1000
  };

  const resp = await fetch("https://api.openai.com/v1/responses", {
    method: "POST",
    headers: {
      ...headers(env),
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });

  const json = await resp.json();
  
  // Parse response from output array
  const messageItem = json.output?.find((item: any) => item.type === "message");
  const contentItem = messageItem?.content?.find((c: any) => c.type === "output_text");
  return contentItem?.text || "";
}

// Usage example:
const answer = await chat(env, "Explain the difference between R2 and D1.");
```

---

## 3. Streaming Responses (Token streaming via SSE)

> For fast UX or R2 file processing, Workers streams tokens beautifully.

```ts
export async function streamChat(env: Env, prompt: string) {
  const resp = await fetch("https://api.openai.com/v1/responses/stream", {
    method: "POST",
    headers: {
      ...headers(env),
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "gpt-5.1",
      input: [{ role: "user", content: prompt }],
      reasoning: { effort: "medium" },
      text: { verbosity: "low" }
    }),
  });

  const reader = resp.body!.getReader();
  const decoder = new TextDecoder();

  let text = "";
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    const chunk = decoder.decode(value);
    text += chunk;
    // Optionally: yield chunk to the client stream
  }
  return text;
}
```

---

## 4. Attachments: Files, PDFs, Images

**Important:** For GPT-5.1 and the Responses API, you must upload files to the **Files API** first, then reference them by `file_id`.

### 4A. Multipart Helper for Workers

> Workers can build multipart bodies directly—no NPM deps required.

```ts
export function buildMultipart(parts: Record<string, any>) {
  const boundary = "----cf-" + crypto.randomUUID();
  const chunks: (string | Blob | Uint8Array)[] = [];

  for (const [name, value] of Object.entries(parts)) {
    if (Array.isArray(value)) {
      for (const item of value) {
        appendPart(chunks, boundary, name, item);
      }
    } else {
      appendPart(chunks, boundary, name, value);
    }
  }

  chunks.push(`--${boundary}--`, "");

  return {
    body: new Blob(chunks),
    boundary
  };
}

function appendPart(chunks: (string | Blob | Uint8Array)[], boundary: string, name: string, value: any) {
  chunks.push(`--${boundary}`);

  if (value instanceof File) {
    chunks.push(
      `Content-Disposition: form-data; name="${name}"; filename="${value.name}"`,
      `Content-Type: ${value.type || "application/octet-stream"}`,
      "",
      value
    );
  } else {
    chunks.push(
      `Content-Disposition: form-data; name="${name}"`,
      "",
      typeof value === "string" ? value : JSON.stringify(value)
    );
  }
}
```

### 4B. Upload File to OpenAI (Files API)

```ts
async function uploadFile(env: Env, file: File): Promise<string> {
  const { body, boundary } = buildMultipart({
    file,
    purpose: "assistants"
  });

  const resp = await fetch("https://api.openai.com/v1/files", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
      "Content-Type": `multipart/form-data; boundary=${boundary}`
    },
    body
  });

  const json = await resp.json();
  return json.id; // Returns file_id (e.g., "file-abc123")
}
```

### 4C. Call Responses API with File ID

```ts
// Step 1: Upload file
const fileId = await uploadFile(env, myFile);

// Step 2: Call Responses API
const resp = await fetch("https://api.openai.com/v1/responses", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-5.1",
    input: [
      {
        role: "user",
        content: [
          { type: "input_file", file_id: fileId },
          { type: "input_text", text: "Summarize this file." }
        ]
      }
    ],
    reasoning: { effort: "medium" }
  })
});
```

---

## 5. Handling Direct User Uploads

> Got a POST with a file? Upload it first, then chat.

```ts
const form = await request.formData();
const file = form.get("file") as File;

// 1. Upload to OpenAI
const fileId = await uploadFile(env, file);

// 2. Chat with context
const resp = await fetch("https://api.openai.com/v1/responses", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-5.1",
    input: [
      {
        role: "user",
        content: [
          { type: "input_file", file_id: fileId },
          { type: "input_text", text: "Extract all dates from this document." }
        ]
      }
    ]
  })
});
```

---

## 6. Multi-Turn Chat (D1 + GPT-5.1)

> Store each chat round in D1; replay ordered history to the model.

**Schema:**

```sql
CREATE TABLE chat_messages (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  session_id TEXT,
  role TEXT,
  content TEXT,
  ts INTEGER
);
```

**Load & Send:**

```ts
const rows = await env.DB.prepare(
  "SELECT role, content FROM chat_messages WHERE session_id=? ORDER BY id"
).bind(sessionId).all();

const resp = await fetch("https://api.openai.com/v1/responses", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-5.1",
    input: rows.map(m => ({
      role: m.role,
      content: m.content
    })),
    reasoning: { effort: "medium" },
    text: { verbosity: "low" }
  })
});

const out = await resp.json();
const messageItem = out.output?.find((item: any) => item.type === "message");
const contentItem = messageItem?.content?.find((c: any) => c.type === "output_text");
const outputText = contentItem?.text || "";

await env.DB.prepare(
  "INSERT INTO chat_messages (session_id, role, content, ts) VALUES (?, ?, ?, ?)"
).bind(sessionId, "assistant", outputText, Date.now()).run();
```

---

## 7. Best Practices for Email2ChatGPT

1. **REST everywhere:** Simpler and snappier.
2. **Stream if possible:** Workers stream natively.
3. **R2 for all binary:** D1 is for metadata, not blobs!
4. **Shorten context:** Summarize threads—don’t replay deep history.
5. **File size checks:** Workers have blob limits; check before send.

---

## 8. Full Example: Worker Endpoint with Optional File

```ts
export const onRequestPost: PagesFunction<Env> = async ({ request, env }) => {
  const form = await request.formData();
  const prompt = form.get("prompt") as string;
  const file = form.get("file") as File | null;

  let userContent: any[] = [{ type: "input_text", text: prompt }];

  if (file) {
    // Upload file first
    const { body, boundary } = buildMultipart({ file, purpose: "assistants" });
    const uploadResp = await fetch("https://api.openai.com/v1/files", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
        "Content-Type": `multipart/form-data; boundary=${boundary}`
      },
      body
    });
    const uploadJson = await uploadResp.json();
    
    // Add file reference
    userContent.unshift({ type: "input_file", file_id: uploadJson.id });
  }

  const resp = await fetch("https://api.openai.com/v1/responses", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "gpt-5.1",
      input: [{ role: "user", content: userContent }],
      reasoning: { effort: "medium" },
      text: { verbosity: "low" }
    })
  });

  const out = await resp.json();
  const messageItem = out.output?.find((item: any) => item.type === "message");
  const contentItem = messageItem?.content?.find((c: any) => c.type === "output_text");
  return new Response(contentItem?.text || "", { status: 200 });
};
```

---

**Note:** Use REST endpoints (`/v1/responses`, `/v1/responses/stream`) for all GPT-5.1 work in Email2ChatGPT on Workers—avoid the Node SDK for best cold starts and less config.

---
